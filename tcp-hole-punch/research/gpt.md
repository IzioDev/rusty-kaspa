Bridging Kaspa P2P with libp2p Hole Punching
This report outlines a plan for enabling two Kaspa nodes behind NAT to form a direct P2P session via libp2p TCP hole punching. It covers six focus areas (Tonic integration, libp2p stream extraction, addressing/identity, runtime integration, failure modes, and security considerations), citing relevant APIs and examples from the Rust ecosystem. Recommendations and open questions are noted in each section, followed by an appendix of references.
Focus 1 – Tonic over Custom Transports
Tonic client and server support for custom I/O: The Rust gRPC library Tonic provides APIs to run over arbitrary async streams. On the client side, tonic::transport::Endpoint::connect_with_connector allows constructing a Channel with a user-provided connector (implementing MakeConnection<Uri>). This means instead of the built-in TCP dial, we can supply a connector that yields an AsyncRead + AsyncWrite stream (for example, a pre-established libp2p substream). Tonic includes an example of using this for UDS (Unix Domain Sockets), which is analogous to plugging in a libp2p connection. There is also a connect_with_connector_lazy variant for non-async connectors.
On the server side, we can bypass binding a TCP socket by using tonic::transport::Server::serve_with_incoming. This API accepts an incoming stream of connections, where each item implements AsyncRead + AsyncWrite + Connected. In practice, we can create a Stream that yields Ok(libp2p_stream) whenever a libp2p connection is ready, and feed that to serve_with_incoming. Tonic will spawn the gRPC service on each such stream as if it were an accepted socket. This is ideal for handling inbound libp2p connections within the existing Kaspa gRPC service framework. (There is also serve_with_incoming_shutdown to attach a shutdown signal.)
Remote address handling: One caveat is that when using a custom stream, the usual socket peer address may not be available. Tonic addresses this via the Connected trait, which custom IO types can implement to provide connection metadata like remote_addr(). For example, Tonic’s default TCP listener wraps streams in an AddrStream that implements Connected to return the peer SocketAddr. If we wrap a libp2p substream, we should implement Connected for it. We may not always have a real SocketAddr (e.g., if the connection went through a relay or is identified only by PeerId), but we could fake it if needed – for instance, using the observed IP and an ephemeral port, or 0.0.0.0:0 as a placeholder. This is important if Kaspa’s P2P code uses the socket address (for logging, peer identification, etc.). We should flag that using libp2p may mean the “real” IP is unavailable or not meaningful in some cases. Kaspa will need to decide if a dummy address is acceptable or if the design should avoid relying on SocketAddr for peer identity.
Relevant prior work: Integrating gRPC over custom transports has been done in the Rust ecosystem. Notably, libp2p-grpc-rs demonstrates running Tonic over libp2p streams. It defines a wrapper for libp2p’s stream that implements tokio::io::AsyncRead and AsyncWrite, and uses Endpoint::connect_with_connector to feed that stream into Tonic. On the server side, it would similarly use serve_with_incoming. Another example is the tarpc project, which can run RPC over any AsyncRead+Write. These precedents indicate we can reuse Tonic’s core machinery without forking it – by implementing the connector and Connected interfaces as needed. In summary, Tonic already supports custom transports, so we can bridge a libp2p connection to Kaspa’s gRPC service with minimal friction. We just need to handle the remote address carefully (possibly synthesizing one) and ensure the AsyncRead/Write from libp2p is compatible (which Focus 2 covers).
Focus 2 – libp2p Stream Extraction (DCUtR to Raw I/O)
Flow from hole-punch to stream: In libp2p, when a direct connection upgrade through relay (DCUtR) succeeds, a new direct connection is established between the two peers. Under the hood, libp2p will negotiate encryption (e.g. Noise or TLS) and multiplexing (e.g. Yamux) on this connection. From the perspective of our application, we don’t immediately get a raw TcpStream; instead, libp2p manages this connection in its swarm. We need to retrieve a substream that we can plug into Kaspa’s router. The typical way is to define a custom protocol for the Kaspa P2P messages. We could, for example, register a protocol name like /kaspa/kaspad-message/1.0 within a NetworkBehaviour. When two libp2p peers connect, they will negotiate supported protocols. If both support the Kaspa protocol, libp2p will open a substream for it. Our custom behaviour’s ConnectionHandler (formerly called ProtocolsHandler in older libp2p versions) will be invoked for this protocol on each connection.
To capture the raw stream, we can implement the ConnectionHandler so that when a Kaspa protocol stream is opened, it delivers the underlying I/O stream to us. In rust-libp2p, an inbound substream is represented by a NegotiatedSubstream type (an alias for an I/O object that implements AsyncRead + AsyncWrite). We can design the handler to simply report an event with the substream. The NetworkBehaviour can then emit this event to the outside. For example, our behaviour might have an event KaspaStreamAccepted { peer: PeerId, stream: NegotiatedSubstream }. The application (outside the Swarm) can poll the swarm’s events and when it sees this, it takes over the stream.
Traits involved: Key traits in this flow are NetworkBehaviour (which defines our protocol and how to handle events), and ConnectionHandler (which manages per-connection substreams). We do not need to implement a custom StreamMuxer – we will use the existing multiplexers (Yamux/Multiplex) provided by libp2p. We rely on libp2p’s DCUtR upgrade protocol (which is itself implemented as a behaviour internally) to trigger the direct connection. Once the direct TCP connection is in place, libp2p’s Swarm will automatically negotiate our Kaspa protocol on it (just as it would on any connection). At that point, our ConnectionHandler produces the substream. We effectively hijack the substream at the earliest point of protocol negotiation.
Compatibility with Tokio/Tonic: The NegotiatedSubstream we obtain implements futures::io::AsyncRead and AsyncWrite. In the context of Tokio, we might need to convert it to a tokio::io::AsyncRead/AsyncWrite. Fortunately, futures-0.3 AsyncRead/AsyncWrite is mostly compatible with Tokio’s traits (Tokio can work with anything that implements those and is Unpin + Send). We should ensure the stream is Send + 'static because Tonic requires the stream to be static (it will live in a spawned task). Libp2p’s substreams are not Send by default because they carry a lifetime tied to the swarm’s executor. Workaround: We can box the substream in an Arc<Mutex<...>> or use channels to transfer ownership. The libp2p-grpc-rs adapter does exactly this: it wraps the NegotiatedSubstream in a new type and uses an internal channel to hand it off to the Tonic connector future, thereby satisfying the 'static lifetime[1]. In practice, once we isolate the substream from the Swarm (by stopping libp2p from reading it further), it behaves like an independent bidirectional stream. It is full-duplex and can be used concurrently for reading and writing (Tonic/h2 will do so). We should double-check that the libp2p stream’s buffers are managed appropriately (they are, by the multiplexer) and that back-pressure is honored – libp2p’s Yamux will apply backpressure on the TCP connection if the substream is not being read, so it should be fine.
Example references: The libp2p-grpc adapter’s code confirms this approach. It defines a NegotiatedStreamWrapper that simply derefs to the libp2p NegotiatedSubstream and implements AsyncRead and AsyncWrite by forwarding to the inner stream. They also implement tonic’s Connected for this wrapper (though they leave remote_addr as None in their example). When an outbound dial is made, they wait for the libp2p connection, then send the substream into a oneshot channel that the Tonic connector is polling – thereby yielding a Channel when the stream is ready. This confirms that the libp2p substream can be cleanly handed to Tonic, meeting all requisite traits. We will adopt a similar strategy: intercept the substream via a behaviour event, wrap it (or simply impl the traits for it) and feed it into the Kaspa router logic via Tonic.
Focus 3 – Address & Identity Derivation
Libp2p addressing after hole punching: Once hole punching succeeds, each node will see a new direct connection to the other. Libp2p will report this connection with endpoint information. Each connection in libp2p has a RemoteAddr (a multiaddr) and an associated PeerId (the cryptographic peer identity). For example, Peer A might see Peer B’s connection as coming from /ip4/203.0.113.5/tcp/61820 (an ephemeral port on B’s NAT) along with Peer B’s PeerId. Additionally, during the DCUtR protocol, peers exchange their known listen addresses. The Connect message sent over the relay contains the sender’s observed addresses. So even before the direct socket is established, A learns what B thinks its external address is (and vice versa). Libp2p’s Identify protocol and AutoNAT also help here: Identify will tell us the observed addresses of a peer as seen by others, and AutoNAT can confirm reachability. In summary, libp2p exposes: - The peer’s PeerId (a hash of its public key, e.g. Qm... in base58 form). - One or more Multiaddr for the peer, which could be a relay address (/p2p-circuit/...) or direct address (/ip4/x.x.x.x/tcp/port/...) depending on connectivity. - An observed address for ourselves (what IP/port others see for us).
Mapping to Kaspa’s NetAddress and PeerKey: The Kaspa node currently uses NetAddress (essentially an IP address and port pair) to identify peers’ network locations, and PeerKey to identify peers (which includes an identity and an address). According to Kaspa’s code, PeerKey::new takes an identity (of type PeerId) and an IpAddress. This suggests Kaspa already envisions peers having a stable identity (likely derived from a public key or node ID) separate from their address. We should leverage libp2p’s PeerId for this. Concretely: - We will generate a libp2p identity keypair for each Kaspa node (e.g., an ed25519 key). The PeerId (which libp2p computes as the hash of the public key) will serve as the node identity in the P2P context. - When connecting, if the remote is using libp2p, we get their PeerId in the handshake. We can then construct Kaspa’s PeerKey from that PeerId and the IP address. The IP could be the remote’s advertised address from their Version message or the socket’s address. (Kaspa’s Version message likely contains the node’s own address and services, similar to Bitcoin’s version handshake.) - If the peer is reached via hole punching, the IP we see will be an ephemeral NAT address. It might change on the next connection. However, the PeerId remains the same for that node across restarts (assuming they use a persistent key). So PeerId should be the primary way to recognize a peer, not IP. We may use a dummy placeholder for the IP in PeerKey if necessary, or update it each time.
Stable IDs or fallbacks: In scenarios where we only have a multiaddr (e.g., /p2p-circuit/... with no direct IP), we still have the PeerId from the multiaddr (.../p2p/<PeerId> component). That PeerId can serve as a stable identifier. Kaspa might need to relax any assumptions about IP uniqueness – historically, nodes often used IP as identifier, but in modern P2P networks that’s not reliable for NAT-ed nodes. We propose: - Use libp2p PeerId as the unique peer identifier (this aligns with Ethereum 2.0, IPFS, and other modern networks). - Use IP addresses only for auxiliary purposes (geolocation, logging, or when communicating with legacy nodes). - If Kaspa’s address manager needs to store addresses for reconnect, store the multiaddr (which could be a direct /ip4 or a /p2p-circuit for fallback). Multiaddr is more expressive: it can include both relay and direct address info.
In practice, after a successful direct connection, both peers can update their address manager entries. For example, Node A, which previously only had Node B’s relay address, now learns B’s actual external IP and port. We can create a NetAddress from that and mark it as a possible future dial address. But because that port might not be open unless punching is coordinated, it’s not a guaranteed dial target. Instead, we’d typically attempt a hole punch again in the future using the relay method, not blindly dial the old port (unless one side became public).
Recommendation: Align Kaspa’s PeerKey with libp2p’s identity system. Possibly extend PeerKey to include the libp2p PeerId (which may internally be or derive from the existing PeerId type in Kaspa – if not, we introduce it). Ensure that handshake verifies the identity (libp2p’s noise handshake already does). Treat matching PeerIds as the criterion for recognizing a peer as “the same” across reconnections, rather than IP. This will require changes in peer management (e.g., to avoid counting the same node twice if it comes on a new IP). It’s an architectural improvement for Kaspa’s network: it prevents simple Sybil rotations by IP, since identity keys are harder to churn than IP addresses.
Focus 4 – Runtime Integration Sketch
Running libp2p Swarm alongside Kaspa’s tasks: Kaspa’s node (rusty-kaspa) uses Tokio for async tasks (the P2P adaptor, gRPC server, etc., all run in the Tokio runtime). We can integrate libp2p’s Swarm in the same runtime. The libp2p Swarm is itself a Stream of events (it implements Stream trait), or we can drive it by continuously polling it. A common pattern is to spawn a task that calls something like:
loop {
   let event = swarm.select_next_some().await;
   handle_event(event);
}
This keeps the Swarm’s networking progressing. We will do this inside the Kaspa node process. Because libp2p may use its own timers and sockets under the hood, it’s important that we use Tokio’s compat features (the default TCP transport in libp2p can be configured for Tokio).
Task ownership and shutdown: We should encapsulate the Swarm in a struct (perhaps within the P2P adaptor) that can be started and stopped. On node startup, create the Swarm (with the necessary transports, keys, and behaviours for relay, AutoNAT, our Kaspa protocol, etc.) and spawn the polling loop. On shutdown, we can simply drop the Swarm handle; libp2p will close sockets. We might also send a shutdown message to the swarm task to terminate the loop gracefully. One way is to use Swarm::disconnect_peer for all, but since dropping is fine, a simple approach is to select the swarm future with a shutdown signal.
Communication between the Swarm task and the rest of the node: We will need a channel (or some interface) for commands: - Dial requests: When the Kaspa adaptor wants to connect to a peer via libp2p (say, after trying the old method or when it knows the peer is behind NAT), it should signal the swarm task. For example, we maintain an async mpsc::Sender<SwarmCmd> where SwarmCmd::DialPeer(PeerId, Vec<Multiaddr>) is one variant. The swarm task, in its loop, will listen on a corresponding Receiver and execute commands (like calling Swarm::dial or Swarm::dial_many accordingly). Libp2p’s dial is async; the swarm will emit an event when the connection (or attempt failure) occurs. - Incoming connection events: When libp2p establishes a new connection (either because we dialed or the other peer dialed us), our custom behaviour will produce an event if the Kaspa protocol stream is opened. The swarm loop will catch this as something like SwarmEvent::Behaviour(KaspaEvent::KaspaStreamAccepted { peer, stream }). At that point, we need to hand this stream to Kaspa’s router. We could send it through another channel: e.g., an mpsc::Sender<IncomingKaspaStream> that the adaptor is waiting on. Alternatively, we integrate directly with Tonic’s server as mentioned in Focus 1: have an UnboundedReceiver of incoming streams hooked into serve_with_incoming.
Concretely, one design is: - The P2P adaptor starts Tonic server with serve_with_incoming using an UnboundedReceiver<io::Result<Libp2pStream>> as the incoming stream source. Initially, this receiver is empty. - When the swarm task gets a KaspaStreamAccepted(stream) event, it sends Ok(stream_wrapper) into the UnboundedSender side. This wakes up the Tonic server, which then spawns a handler for that stream and performs the Kaspa handshake over it. - For outgoing connections, the adaptor can either be the one initiating the handshake (acting as client) or server. Typically, Kaspa might designate the dialer as the client. In that case, when we dial via libp2p, we don’t use serve_with_incoming (since that’s for servers); instead, once we have the substream, we use Endpoint::connect_with_connector to create a client Channel on it (like the libp2p-grpc approach for outbound). The adaptor can then run the handshake procedure by sending the Version message, etc.
Back-pressure and error propagation: Integrating two async systems means we have to handle back-pressure signals. Libp2p’s swarm has internal buffers but generally expects us to read events promptly. If the adaptor for some reason stopped reading incoming streams (unlikely, since Tonic will always be reading as long as the stream is active), libp2p’s yamux would apply back-pressure on the TCP level. We should ensure the swarm task isn’t blocked on sending events to the adaptor. Using an unbounded channel for incoming streams (or bounded with a reasonable size) helps – if it ever fills, we might apply back-pressure by not accepting new connections until the router catches up. But the volume of connections is not expected to be extremely high (a Kaspa node might have on the order of tens of connections, not thousands).
When a dial attempt fails (e.g., relay not available, or hole punch failed), libp2p will emit an error event (SwarmEvent::OutgoingConnectionError or a Behaviour event if DCUtR explicitly signals failure). We should catch these and propagate them. For instance, if the adaptor called dial_via_libp2p(peer), we can have it await a oneshot that the swarm task will fulfill. The swarm task, on success, sends back the stream (triggering the Channel creation), or on failure sends back an error. This requires a bit of orchestration (similar to how the libp2p-grpc example uses a channel to feed the stream into the connector future).
API surface proposal: We expose in the P2P adaptor a method like async fn connect_via_libp2p(&self, peer_id: PeerId, addr: Multiaddr) -> Result<Router, Error>. This method sends the dial command and then awaits the outcome (either a stream to build a Router, or an error). The Router is Kaspa’s abstraction for a peer connection (backed by a tonic Channel or Server streaming call). If the connect succeeds, we perform the Kaspa handshake on this Router just as if it were a normal TCP/gRPC connection. If it fails, we return an error so the higher-level logic can decide to fallback (perhaps try a different method or schedule a retry).
Threading and context: All of this can happen on the main Tokio executor. No separate thread is strictly required for libp2p. However, if Kaspa’s node is heavily CPU-bound, we might consider running the libp2p Swarm on a dedicated thread to avoid jitter (Tokio multi-threaded runtime should largely alleviate this). The important thing is to coordinate shutdown: when Kaspa node is shutting down, signal the swarm loop to exit (so it doesn’t hold the process). Also, on shutdown, close any open libp2p streams gracefully if possible, so that peers know we disconnected (though in practice, if we just drop, the peers’ transports will realize the connection is gone).
In summary, the integration will treat the libp2p Swarm as a subordinate async task that the Kaspa adaptor controls via message passing. This keeps the concerns separated: libp2p handles networking and NAT traversal; Kaspa’s adaptor remains in charge of when to initiate or accept a connection (just now with more options). The design ensures that from the Kaspa router’s perspective, it still gets a stream of KaspadMessages it can read/write – it won’t care whether those come from a raw TCP or a libp2p stream.
Focus 5 – Failure Modes & Fallbacks
Success/failure signals in libp2p NAT traversal: libp2p’s hole punching (DCUtR) is largely transparent to the application. The sequence is: peers connect via a relay, coordinate, then each peer’s networking stack attempts a simultaneous TCP open. If successful, a direct connection is added to the Swarm. If it fails, the peers continue communicating over the relay (unless configured otherwise). There isn’t a high-level “hole punch failed” callback; failure is inferred by the absence of a new direct connection after some time. However, libp2p developers have shared typical outcomes: overall, about 70% of attempted NAT hole punches succeed across diverse real-world networks[2]. This indicates a significant fraction of cases (30%) will remain on relays unless another strategy is tried.
Success rates by NAT type: The success probability heavily depends on the NAT types of the two peers. If at least one peer is in a favorable condition (e.g., one is fully public or has a full-cone NAT), direct TCP usually works. The worst case is two symmetric NATs with highly randomized ports – this often fails for TCP. A Protocol Labs study (Hole Punching Measurement Campaign) found ~70% average success, and further experiments showed TCP hole punching succeeded in ~86% of attempts in a testbed (with a variety of NATs), while QUIC punching succeeded ~93%. Those higher numbers likely exclude the most restrictive NATs. The key point is that a substantial minority of connections will not succeed via hole punching. libp2p will give up after its configured attempts (by default, it tries the synchronized open once; it may retry once more if the first attempt fails, but not indefinitely).
Detection timing – when to give up: Empirically, if a hole punch hasn’t succeeded within a few seconds, it likely won’t. The process is fast: peers coordinate, then within one RTT they start sending SYN packets. If no SYN crosses (due to NAT blocking), they might retry once using perhaps a different port guess (libp2p’s DCUtR as implemented doesn’t currently do port prediction beyond the first observed ports, to my knowledge). Research indicates that the vast majority of successful hole punches succeed on the first try, and trying more than 3 times yields no improvement. So we can decide to give up relatively quickly – on the order of 1–2 seconds after coordination – and resort to fallback. Libp2p likely already closes the coordination channel after one attempt; thus, as application developers, our role is to detect that we’re still on a relay after a timeout and then initiate a fallback.
Fallback options: 1. Use QUIC for direct connect: QUIC (which libp2p supports as a transport) has a built-in NAT traversal edge: because QUIC runs over UDP, some NATs that randomize TCP ports might still allow UDP hole punching. Also, QUIC doesn’t require a simultaneous open in the same way (though one side still has to act as “server”). libp2p’s hole punch coordination can also coordinate QUIC (the DCUtR spec has a QUIC variant). If both peers support QUIC, we can attempt a QUIC connection as an alternative path. Success rates for QUIC were measured higher than TCP’s. However, note that about 5–10% of networks block UDP entirely, so QUIC is not a panacea. We should include QUIC in our transport stack for libp2p. A sensible approach: try hole punching with TCP; if it fails, libp2p could automatically try QUIC (this might require configuring two transport attempts). 2. Stay on Relay (Circuit Relay): If direct connection fails, the last resort is to use the relay indefinitely. Libp2p relays (v2) are designed to carry traffic if needed, but with limitations. The relay protocol intentionally limits bandwidth and duration for relayed connections, to prevent them from being a permanent solution. In IPFS, relays drop idle or long-lived streams to avoid abuse. We need to consider that for Kaspa: can a relay support the bandwidth of block and transaction data? Possibly, but not ideal. If we must stay on a relay, we may want to gracefully degrade what data we send (maybe avoid sending bulk historical sync data over relays, if possible). In any case, the adaptor should monitor if it’s on a relayed connection and maybe periodically retry establishing a direct connection in the background (libp2p can do this via periodic AutoNAT checks and DCUtR retries). 3. Alternative strategies: If both TCP and QUIC fail and relays are slow, there are not many other options without external help. Some projects use UDP hole punching with ICE (STUN/TURN), but libp2p explicitly avoids centralized servers. In our context, since we already have a relay connection, using it is equivalent to using a TURN server (just decentralized). Another fallback could be to try a completely different relay. If two peers are having trouble via one relay, perhaps a different relay might yield a different NAT mapping that works (this is hypothetical – generally, if the NATs are symmetric, any direct attempt will fail unless one can predict the port, which libp2p doesn’t do extensively).
Heuristics to limit resource waste: Hole punching attempts cost some overhead (CPU to coordinate, and possibly a flurry of SYN packets). Relays cost bandwidth on third-party nodes. To prevent abuse or waste: - We should avoid repeated failed attempts in a short period. If we know a given peer’s NAT type combination is likely un-punchable (for example, after 1-2 failures), we might stick to relay for a while (e.g., 10 minutes) before retrying a punch. libp2p doesn’t automate repeated tries by default; it’s usually one-and-done per connection. So any retries would be on us to initiate (perhaps by reconnecting via relay and trying again). - Implement a timeout for the hole punch process. If no direct connection emerges after, say, 5 seconds of initiating DCUtR, consider it failed. (Five seconds is generous; likely it either succeeds in <1s or not at all). - Use AutoNAT to gauge feasibility. AutoNAT can tell us if we are undialable from outside. If both peers are undialable (symmetric NAT), the odds of TCP hole punch are low. In such cases, maybe don’t even try (or try QUIC which has slightly better odds). This heuristic could save time, though the cost of trying a punch is not huge – so it might be acceptable to just try anyway since libp2p already does the signaling. - Monitor relay usage: if relays become a bottleneck (perhaps many peers stuck on relays), consider deploying more relays or encouraging peers to enable UPnP/PCP on their routers if possible to become dialable. (This last point is more of a network operational consideration than something we implement in code.)
Exploit or abuse scenarios: One potential abuse is an attacker could attempt to force many hole punch attempts to consume a node’s resources (e.g., constantly connecting via relay and dropping before completion). We should ensure that initiating a hole punch (DCUtR) has some rate-limit. libp2p likely doesn’t expose a direct API for us to allow or disallow DCUtR per peer – it’s automatic on relayed connections. But we can rate-limit how often we allow incoming relayed connections from the same peer, etc. Another scenario is an attacker using our node as a relay excessively (if we are public); we handle that in Focus 6 with relay policy. Overall, by bounding attempts and using the aforementioned fallbacks prudently, we can achieve a robust connection mechanism where hole punching is attempted when beneficial and quickly falls back to other methods to minimize impact on message propagation.
Focus 6 – Security & Abuse Considerations
Relay trust model: By introducing relays and hole punching, we rely on third-party nodes for initial connectivity. In libp2p, any public node can act as a relay by offering the service. This raises the question: should Kaspa nodes trust arbitrary IPFS bootstrap relays or run a set of dedicated relays? Using random relays adds resilience (decentralization) but also risk – a malicious relay could drop all traffic to certain peers (performing an eclipse by isolating a subset of nodes that rely on it). However, note that even a malicious relay cannot read or modify Kaspa messages, since libp2p’s noise encryption secures the traffic. The main risk is denial of service or traffic analysis. A strategy to mitigate relay risk is: - Use multiple relays: A node behind NAT should reserve with 2 or more relays in different regions/providers. If one relay misbehaves, the other can carry traffic or assist in punching. Libp2p supports multiple reservations (and will advertise multiple relayed addresses). The hole punch coordination can happen over any of them. - Prefer well-known relays: The Kaspa community could maintain a few stable relays (perhaps run by trusted community members or the foundation). Nodes could default to those for reliability. This is similar to how Ethereum’s discovery uses known bootnodes. The presence of known relays reduces dependency on unknown infrastructure. It does introduce some centrality, so it’s a trade-off. - Periodic relay rotation: To avoid long-term reliance on a single relay, nodes could switch or add relays periodically (say every hour, get a new reservation somewhere). This makes it harder for an attacker to target a node’s all relays over time.
Rate limiting connections and reservations: A public Kaspa node (not behind NAT) will likely run the libp2p Relay server behaviour (unless disabled). By default, the relay behaviour limits resource usage. For example, it can limit the number of active relay connections and the number of reservations it grants. We should configure these limits in line with Kaspa’s expected peer count: - If a Kaspa node is public, it might allow, say, up to 100 reservations (meaning up to 100 NATed peers can use it as a relay). This number can be adjusted; too high and it could consume memory/bandwidth, too low and it rejects otherwise healthy peers. We should monitor what fraction of peers are NATed to choose a good default. - Limit relayed traffic: The relay spec allows setting a max data throughput or duration for relayed connections. IPFS, for instance, might limit each relayed connection to 5 minutes unless hole punching succeeds, and throttle bandwidth. We might allow a longer duration for Kaspa relays because peer turnover is costly for blockchain sync. Perhaps allow relayed connections to persist but at a reduced bandwidth (to encourage punching for full speed). Configurable knobs like max_relayed_connections, max_reserved_slots, max_relay_bandwidth should be exposed in the node config. - Outbound dialing rate: Additionally, to prevent spamming other peers, we could rate-limit how often we initiate outbound dials or hole-punch attempts, especially to the same peer or via the same relay.
Anti-eclipse and network health: Eclipse attacks attempt to isolate a node by controlling all its connections. Libp2p integration can both help and hurt here: - On one hand, having relays and hole punching increases connectivity options, making it harder to completely cut off a node (since even NATed nodes can connect out). - On the other hand, if an attacker runs many relays or peer identities, they could try to occupy all of a node’s connections. To counter this: - Maintain a diverse set of peers. The AddressManager should not exclusively rely on one relay or one address source. Use the DHT (when implemented) or multiple bootstraps to get peer addresses. - Possibly limit the number of connections that come via the same relay. If we notice 8 of our 8 peers are all connected through relay X, that’s a red flag. We could proactively seek out other peers via different relays or direct connections. - Use identity checks: libp2p identities (PeerIds) can be tied to a reputation system. If we find that many connections share the same unusual characteristic (all from the same /16 subnet via a relay), maybe avoid that.
Resource exhaustion attacks: A malicious peer might try to abuse the hole punch protocol to make us waste effort. For example, sending repeated fake Connect/Sync messages. Libp2p’s DCUtR protocol likely has validation (it only works if both sides follow the protocol correctly, and it’s authenticated). We should still ensure that if a peer fails to upgrade after some attempts, we drop the relay connection to not linger. Also, because Kaspa is a blockchain network, we should apply the usual DoS mitigations at the message level (those remain unchanged by libp2p integration, since libp2p is just transport).
Open questions (policy decisions): - Should all public Kaspa nodes serve as relays? This is the default in libp2p (any node not behind NAT can accept relay reservations). The upside: more relays = better connectivity for all. Downside: slight resource cost to those nodes. This can be configurable. We might start with it enabled to bootstrap connectivity, then allow node operators to turn it off if they don’t want to support others. - Relay selection strategy: If relying on the IPFS default, the node will find relays via the DHT (closest peers). This might be suboptimal if those peers are not reliable. A policy decision is whether to hard-code some relays or use a discovery service. We might initially use a hard-coded list of community relays for simplicity, and later move to dynamic discovery as the network grows. - Allowing direct IP connections: After libp2p integration, do we still allow the old style direct IP gRPC connections? Possibly yes, for backward compatibility or for peers that have public IPs known. Running both in parallel is complex but doable. We could attempt libp2p dial, and if that fails and the peer had an advertised IP, try a direct gRPC dial as fallback (for a transition period). Alternatively, require all nodes to upgrade to libp2p for NAT traversal benefits. This needs discussion. - Peer identity and encryption: Kaspa’s current network might be unencrypted or uses a custom scheme. Libp2p will encrypt all traffic by default. This is good for security. We need to ensure this doesn’t break any ability to inspect traffic if needed (probably not, P2P traffic can remain encrypted). Also, how will we incorporate the libp2p peer public keys into Kaspa’s peer databases? Possibly we don’t need to beyond using PeerId, but if Kaspa had a node authentication mechanism (like masternodes or permissioned list), we’d have to reconcile that with libp2p keys. This seems not the case for Kaspa, but worth confirming.
Overall, the libp2p integration introduces new degrees of freedom in peer connectivity. Setting sane limits (no unlimited relays, no infinite retries, etc.) and possibly leveraging libp2p’s existing defaults (which are designed to prevent abuse) will be important. We highlighted some parameters that Kaspa developers should review – e.g., maximum relay count, idle timeout for relays, and so on. Many of these can be tuned by configuring libp2p’s RelayConfig, SwarmConfig (connection limits), etc., before launching the network. As the network matures, these policies may be revisited based on observed usage and attacks.
 
Appendix: Related Code & References
•	Tonic Custom Transport APIs: Documentation of Tonic’s support for custom I/O transports. The Endpoint::connect_with_connector API is demonstrated in tonic docs, allowing a Channel over a non-TCP connection. Likewise, Server::serve_with_incoming accepts an incoming stream of AsyncRead + AsyncWrite connections, enabling gRPC servers to run on custom listeners. Tonic’s Connected trait can be implemented to provide a remote SocketAddr for custom connections (e.g., to fake an address for libp2p streams).
•	libp2p-gRPC Adapter Example: libp2p-grpc-rs (by 0xbillw) provides an example of bridging libp2p streams into tonic. It wraps libp2p’s NegotiatedSubstream in a struct implementing AsyncRead/Write and tonic’s Connected trait, making it compatible with Tonic. The client side uses Endpoint::connect_with_connector with a custom Service<Uri> that waits for a libp2p substream to be provided. This design effectively hands off a libp2p stream to gRPC when available, illustrating how our integration can be achieved without modifying tonic or libp2p cores.
•	libp2p Connection Lifecycle: The rust-libp2p architecture uses a NetworkBehaviour to manage protocols. Under the hood, each established connection is managed by a ConnectionHandler (formerly ProtocolsHandler in older versions). This handler negotiates protocols and produces events with substreams (represented by NegotiatedSubstream). By implementing a custom behaviour for Kaspa, we can intercept the moment a substream is ready and obtain the raw I/O stream for use in Kaspa’s handshake. No changes to libp2p’s StreamMuxer are needed; we reuse existing ones (mplex or yamux). We just plug into the event when our protocol is opened.
•	NAT Hole Punching Efficacy: Studies and talks on libp2p NAT traversal give insight into success rates. According to Project Iroh’s comparison, libp2p’s decentralized hole punching succeeds around 70% of the time on average[2]. A Protocol Labs research paper (2022) reported even higher success in trials (TCP 86%, QUIC 93%) and noted that most hole punches succeed on the first attempt, with diminishing returns after 3 tries. These data justify our approach to attempt punching but also to implement timely fallbacks for the ~30% of tough cases.
•	Relay and Resource Limits: Libp2p’s Circuit Relay v2 protocol includes built-in limitations to prevent abuse. Documentation highlights that relay nodes restrict the number of active relay connections and reservations, as well as limit their duration and bandwidth. This ensures relays remain a scalable solution. In practice, every public node can act as a relay with minimal overhead due to these limits. We plan to tune these parameters for Kaspa’s network needs. For example, if a Kaspa node serves as a relay, it might only allow a certain number of slots and drop relayed connections after X minutes if no direct connect succeeds. These measures, along with using multiple relays and preferring direct connections whenever possible, form the crux of our strategy to balance connectivity and security.
 
[1] adapter.rs - source
https://docs.rs/libp2p-grpc-rs/latest/src/libp2p_grpc_rs/adapter.rs.html
[2] Comparing Iroh & Libp2p: Simplifying P2P Connectivity - Iroh
https://www.iroh.computer/blog/comparing-iroh-and-libp2p
